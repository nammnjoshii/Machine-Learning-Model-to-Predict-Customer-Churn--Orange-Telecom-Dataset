{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final project - Orange Telecom's churn\n",
    "\n",
    "Nammn Joshii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate,train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "The following dataset is downloaded from Kaggle website: https://www.kaggle.com/mnassrib/telecom-churn-datasets\n",
    "The original dataset has already been splitted into training set(80%) and testing set(20%) in two csv file ('churn-bigml-80.csv' and 'churn-bigml-20.csv') separately. However, when using this preset train set and test set, the final model we established was overfitted. Therefore, we combine a full dataset and redo the training and testing data splitting by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the original data set\n",
    "df = pd.read_csv('churn-bigml-80.csv', index_col=0)\n",
    "df1 = pd.read_csv('churn-bigml-20.csv', index_col=0)\n",
    "#Combine into one dataframe\n",
    "df_full = pd.concat([df,df1], axis=0)\n",
    "\n",
    "#Identify quantitative features and categorical features\n",
    "numeric_features = ['Account length', 'Area code', 'Number vmail messages',\n",
    "                    'Total day minutes', 'Total day calls', 'Total day charge',\n",
    "                   'Total eve minutes','Total night minutes','Total night calls','Total intl minutes','Total intl calls',\n",
    "                    'Total intl charge']\n",
    "categorical_features = ['International plan', 'Voice mail plan']\n",
    "\n",
    "\n",
    "#Use OneHotEncoder to change categorical features into dummies\n",
    "#The code below about OHE refers to the lecture notes of UBC Sauder MBAN course BAIT 509 Business Applications of Machine Learning lecture 5 from Tomas Beuzen.\n",
    "enc = OneHotEncoder(handle_unknown='error', drop='first',categories='auto',sparse=False)\n",
    "le = preprocessing.LabelEncoder()\n",
    "X1 = df_full.apply(le.fit_transform)\n",
    "X = X1.drop(columns=['Churn'])\n",
    "\n",
    "#Use OneHotEncoder to change categorical targets into dummies\n",
    "enc_df=enc.fit_transform(df_full[['Churn']])\n",
    "df_full['Churn1']=enc_df\n",
    "y=df_full['Churn1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define X and y in the training dataset and the testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X_train and X_test\n",
    "#We use the column \"churn\" as the target, and rest of the columns as features\n",
    "#The code below about train_test_split refers to the lecture notes of UBC Sauder MBAN course BAIT 509 Business Applications of Machine Learning lecture 2 from Tomas Beuzen.\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection\n",
    "We tried naive bayes, decision tree classifier, logistic regression, Knn classifier and random forest classifier for model selection. For all models, we use gridsearchCV to test the optimal hyperparameters and use k=5 for cross validation. The model with the lowest cross validation error is the best model to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st try: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best multinomial naive bayes model's cross validation error = 0.41\n"
     ]
    }
   ],
   "source": [
    "#Try Naive Bayes model for prediction\n",
    "#Use GridSearchCV to look through a list of hyperparameters(different alpha) and use cross validation with k=10\n",
    "\n",
    "#The code below about GridSearchCV refers to the lecture notes of UBC Sauder MBAN course BAIT 509 Business Applications of Machine Learning lecture 1 - lecture 9 from Tomas Beuzen.\n",
    "hyperparams = {'alpha': [0.1, 0.5, 1]}\n",
    "model = MultinomialNB()\n",
    "model_grid = GridSearchCV(model, hyperparams, cv=5)\n",
    "\n",
    "#fit the decision tree with the X_train and the best decision tree model in GridSearchCV\n",
    "best_model = model_grid.fit(X_train, y_train)\n",
    "print(f\"The best multinomial naive bayes model's cross validation error = {1 - best_model.best_score_:.2f}\")\n",
    "# The cross validation error rate is too high and we are not working on the further development of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd try: Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best decision tree model's cross validation error = 0.06\n"
     ]
    }
   ],
   "source": [
    "#Try decision tree classifier\n",
    "#Use GridSearchCV to look through a list of hyperparameters(different max_depth etc) and use cross validation with k=5\n",
    "hyperparams = {'max_depth': [3, 5, 10,15, 20],\n",
    "               'criterion': ['gini', 'entropy'],\n",
    "               'min_samples_leaf': [2, 4]}\n",
    "model = DecisionTreeClassifier(random_state = 123)\n",
    "model_grid = GridSearchCV(model, hyperparams, cv=5)\n",
    "\n",
    "#fit the decision tree with the new X_train and the best decision tree model in GridSearchCV\n",
    "best_model = model_grid.fit(X_train, y_train)\n",
    "print(f\"The best decision tree model's cross validation error = {1 - best_model.best_score_:.2f}\")\n",
    "# The cross validation error is quite low, we can keep this model as a potential option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3rd try: Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic regression's training error rate = 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs').fit(X_train,y_train)\n",
    "#cv = cross_validate(model,X_train,y_train,cv=5)\n",
    "#print(f\"The logistic regression's cross validation error rate = {1 - cv['test_score'].mean():.2f}\")\n",
    "print(f\"The logistic regression's training error rate = {1 - model.score(X_train, y_train):.2f}\")\n",
    "# error rate is higher than the decision tree classifier \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th try: Knn Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best knn classifier model's cross validation error = 0.13\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {'n_neighbors': [1, 3, 5]}\n",
    "knn = KNeighborsClassifier()\n",
    "model_grid = GridSearchCV(knn, hyperparams, cv=5)\n",
    "               \n",
    "best_model = model_grid.fit(X_train, y_train)\n",
    "print(f\"The best knn classifier model's cross validation error = {1 - best_model.best_score_:.2f}\")\n",
    "# error rate is higher than the decision tree classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5th try: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best random forest classifier's cross validation error = 0.05\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {'max_depth': [50,75,100,None],\n",
    "              \"n_estimators\":[100,120,150]}\n",
    "model = RandomForestClassifier(random_state = 1)\n",
    "model_grid = GridSearchCV(model, hyperparams, cv=5)\n",
    "best_model = model_grid.fit(X_train, y_train)\n",
    "print(f\"The best random forest classifier's cross validation error = {1 - best_model.best_score_:.2f}\")\n",
    "#The cross validation error rate is the lowest among all 5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter: {'max_depth': 50, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best hyperparameter: {model_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = RandomForestClassifier(max_depth = 50, n_estimators=120, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide final model\n",
    "Since the random forest classifier has the lowest cross validation error among all 5 models, we decided to use random forest classifier as our final model. The best model according to gridsearchCV is a random forest model with 'max_depth'= 50 and 'n_estimators'= 100. \n",
    "Now we would like to try to simply the model by decreasing the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We tried to use SelectKBest function to reduce the number of explanatory variables.\n",
    "#The code below about selectKbest refers to the lecture notes of UBC Sauder MBAN course BAIT 509 Business Applications of Machine Learning lecture 6 from Tomas Beuzen.\n",
    "selector = SelectKBest(mutual_info_classif, k=6)#Since we have both categorical and quantitive features, we select mutual_info_classif\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_new = selector.transform(X_train)\n",
    "X_test_new = selector.transform(X_test)\n",
    "best_features = selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total day charge</td>\n",
       "      <td>0.062640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Total day minutes</td>\n",
       "      <td>0.061687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Customer service calls</td>\n",
       "      <td>0.040939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International plan</td>\n",
       "      <td>0.018206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number vmail messages</td>\n",
       "      <td>0.013269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total day calls</td>\n",
       "      <td>0.012853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "7         Total day charge    0.062640\n",
       "5        Total day minutes    0.061687\n",
       "17  Customer service calls    0.040939\n",
       "2       International plan    0.018206\n",
       "4    Number vmail messages    0.013269\n",
       "6          Total day calls    0.012853"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'feature': X_train.columns,\n",
    "              'importance':selector.scores_}).sort_values(by='importance', ascending=False).iloc[0:6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validation error with 6 top features = 0.12\n"
     ]
    }
   ],
   "source": [
    "#We firstly try to use the best features selected from SelectKBest.\n",
    "cv = cross_validate(model_final, X_train_new, y_train, cv=5) #X_train_new has only features selected in SelectKBest\n",
    "print(f\"The cross-validation error with 6 top features = {1 - cv['test_score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the reduced features, the cross validation error increased instead, which indicates this is not a good way. Now we tried to use feature importance in random forest classifier to idenity if there is any features we could remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   feature  importance\n",
      "7         Total day charge    0.141974\n",
      "5        Total day minutes    0.138132\n",
      "17  Customer service calls    0.117783\n",
      "2       International plan    0.073823\n",
      "8        Total eve minutes    0.064081\n",
      "10        Total eve charge    0.063848\n",
      "15        Total intl calls    0.055282\n",
      "16       Total intl charge    0.045157\n",
      "14      Total intl minutes    0.043631\n",
      "11     Total night minutes    0.039735\n",
      "13      Total night charge    0.039250\n",
      "0           Account length    0.032547\n",
      "6          Total day calls    0.031284\n",
      "12       Total night calls    0.030003\n",
      "4    Number vmail messages    0.029037\n",
      "9          Total eve calls    0.028835\n",
      "3          Voice mail plan    0.016104\n",
      "1                Area code    0.009492\n"
     ]
    }
   ],
   "source": [
    "model_final.fit(X_train, y_train) #we now still use the original set of X\n",
    "print(pd.DataFrame({'feature': X_train.columns,'importance':model_final.feature_importances_}).sort_values(by='importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validation error with 2 decreased features = 0.05\n"
     ]
    }
   ],
   "source": [
    "# Therefore we drop the least two important features (whose importance level are below 0.02)\n",
    "X_train_final = X_train.drop(columns=['Area code', 'Voice mail plan'])\n",
    "cv = cross_validate(model_final, X_train_final, y_train, cv=5)\n",
    "print(f\"The cross-validation error with 2 decreased features = {1 - cv['test_score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the two least important features, the cross validation error for our final random forest classifier is at a similar level with the cross validation error with full set of features. We consider it is appropriate to simply the model by dropping two least important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final model's testing error rate = 0.05\n"
     ]
    }
   ],
   "source": [
    "model_final.fit(X_train_final,y_train)\n",
    "#X_test_final = X_test.drop(columns=['Area code', 'Voice mail plan'])\n",
    "X_test_final = X_test.drop(columns=['Area code', 'Voice mail plan'])\n",
    "print(f\"Our final model's testing error rate = {1 - model_final.score(X_test_final, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the overall probability of customer churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba = model_final.predict_proba(X_test_final)\n",
    "model_final.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863568215892054\n"
     ]
    }
   ],
   "source": [
    "#Now we would like to calculate how many people have the intention to churn (churn = 1)\n",
    "n_lst=[]\n",
    "for i in range(len(predicted_proba)): \n",
    "    if predicted_proba[i][0]>0.5:\n",
    "        n_lst.append(i)\n",
    "    else:\n",
    "        continue\n",
    "print(len(n_lst)/len(X_test_final))\n",
    "# based on our predictions, that more than 86% of the customers are tend to cancel the subscriptions of telecom plan\n",
    "# we would like to further evaluate the accuracy of our predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification matrix - compared our prediction to real testing set target value for accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([549,   8,  27,  83])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_predicted = (predicted_proba[:,1] >= threshold).astype('int')\n",
    "#The code below refers to https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "confusion_matrix(y_test, y_predicted).ravel() #(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision rate= 83/(83+8)= 0.91 (91% of positive predictions was actually correct.)\n",
    "\n",
    "recall rate =83/(83+27)=0.75 (75% proportion of true positives was identified correctly.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new data and evaluate the impacts of key features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Account length', 'International plan', 'Number vmail messages',\n",
       "       'Total day minutes', 'Total day calls', 'Total day charge',\n",
       "       'Total eve minutes', 'Total eve calls', 'Total eve charge',\n",
       "       'Total night minutes', 'Total night calls', 'Total night charge',\n",
       "       'Total intl minutes', 'Total intl calls', 'Total intl charge',\n",
       "       'Customer service calls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>More total day minutes</th>\n",
       "      <th>Less total day minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Churn: No</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn: Yes</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.158333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            More total day minutes  Less total day minutes\n",
       "Churn: No                      0.8                0.841667\n",
       "Churn: Yes                     0.2                0.158333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#customer 1 with the higher value in total day minutes (4th number in the list)\n",
    "c1=np.atleast_2d([13,0,21,880,105,53.65,208.9,71,17.76,260.1,123,11.7,12.1,3,3.27,3]) \n",
    "#customer with the lower value in total day minutes (4th number in the list)\n",
    "c2=np.atleast_2d([13,0,21,4,105,53.65,208.9,71,17.76,260.1,123,11.7,12.1,3,3.27,3]) \n",
    "\n",
    "pd.DataFrame({'More total day minutes': model_final.predict_proba(c1)[0],\n",
    "              'Less total day minutes': model_final.predict_proba(c2)[0]},\n",
    "             index=['Churn: No', 'Churn: Yes'])\n",
    "# we could see that if the total minutes is longer, the customers are less likely to continue subscribe the telecom plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Less customer service calls</th>\n",
       "      <th>More customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Churn: No</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn: Yes</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Less customer service calls  More customer service calls\n",
       "Churn: No                      0.833333                        0.125\n",
       "Churn: Yes                     0.166667                        0.875"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#customer 3 with the less customer service calls(last number in the list)\n",
    "c3=np.atleast_2d([93,0,22,306.2,123,52.05,189.7,83,16.12,240.3,107,10.81,11.7,2,3.16,0])\n",
    "#customer 4 with the more customer service calls(last number in the list)\n",
    "c4=np.atleast_2d([93,0,22,306.2,123,52.05,189.7,83,16.12,240.3,107,10.81,11.7,2,3.16,9])\n",
    "pd.DataFrame({'Less customer service calls': model_final.predict_proba(c3)[0],\n",
    "              'More customer service calls': model_final.predict_proba(c4)[0]},\n",
    "             index=['Churn: No', 'Churn: Yes'])\n",
    "# we found that customer with lower customer service call will be more likely to continue subscribing to the telecom plan. customer service call is negatively correlated to the subscription rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Less total day charge</th>\n",
       "      <th>More total day charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Churn: No</th>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn: Yes</th>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Less total day charge  More total day charge\n",
       "Churn: No                0.758333                  0.725\n",
       "Churn: Yes               0.241667                  0.275"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#customer 5 with the lower value in total day charge(6th number in the list)\n",
    "c5=np.atleast_2d([64,0,40,210,116,0,232.7,89,19.78,168.8,94,7.6,5.9,4,2.54,0])\n",
    "#customer 6 with the higher value in total day charge(6th number in the list)\n",
    "c6=np.atleast_2d([64,0,40,210,116,1488,232.7,89,19.78,168.8,94,7.6,5.9,4,2.54,0])\n",
    "pd.DataFrame({'Less total day charge': model_final.predict_proba(c5)[0],\n",
    "              'More total day charge': model_final.predict_proba(c6)[0]},\n",
    "             index=['Churn: No', 'Churn: Yes'])\n",
    "# we found that customer with lower total day charge will be more likely to continue subscribing to the telecom plan. \n",
    "# Total day charge is positively related to the subscription rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code reference\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
